{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab794cb2-0f59-40b1-874a-5f396e8d76e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 01 Class exercise slicing dataframe\n",
    "Use this data:\n",
    "```python\n",
    "data = np.array([['','Col1','Col2','col3'],\n",
    "                ['Row1',1,2,3],\n",
    "                ['Row2',4,5,6],\n",
    "                ['Row3',7,8,9]])\n",
    "```\n",
    "1. Create a DataFrame (wrap the data above in a pandas DataFrame in a way that printing the dataframe and its index and column attributes gives this result)  \n",
    "`pd.DataFrame(data=data[1:4,1:4], columns=data[0,1:4], index=data[1:4,0])`  \n",
    "\n",
    "``` \n",
    "     Col1 Col2 col3  \n",
    "Row1    1    2    3\n",
    "Row2    4    5    6\n",
    "Row3    7    8    9\n",
    "\n",
    "Index(['Row1', 'Row2', 'Row3'], dtype='object')\n",
    "Index(['Col1', 'Col2', 'col3'], dtype='object')\n",
    "```\n",
    "\n",
    "2. Make slices of data:\n",
    "   1. second column using column name\n",
    "   2. third column using column index (.iloc[])\n",
    "   3. slice element at third row of second column (use .iloc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc16e8a-db05-4383-aefb-f8dd80987d70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Create a DataFrame (wrap the data above in a pandas DataFrame in a way that printing the dataframe and its index and column attributes gives this result)\n",
      "     Col1 Col2 col3\n",
      "Row1    1    2    3\n",
      "Row2    4    5    6\n",
      "Row3    7    8    9\n",
      "\n",
      "\n",
      "Index(['Row1', 'Row2', 'Row3'], dtype='object')\n",
      "Index(['Col1', 'Col2', 'col3'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from my_modules.pandas_Ex import slicing_dataframe1\n",
    "slicing_dataframe1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829f3a18-c8c1-4037-b1af-aa14112e98bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. second column using column name\n",
      "Row1    2\n",
      "Row2    5\n",
      "Row3    8\n",
      "Name: Col2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from my_modules.pandas_Ex import slicing_dataframe2a\n",
    "slicing_dataframe2a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e31ea5cb-cc36-4b99-9918-84030ac5581d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. third column using column index (.iloc[])\n",
      "Row1    3\n",
      "Row2    6\n",
      "Row3    9\n",
      "Name: col3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from my_modules.pandas_Ex import slicing_dataframe2b\n",
    "slicing_dataframe2b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "425f3d35-7e58-41de-b56e-12821120c209",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. slice element at third row of second column (use .iloc())\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "from my_modules.pandas_Ex import slicing_dataframe2c\n",
    "slicing_dataframe2c()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3739343b-8cbe-4e3f-9984-79751cfbdedd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 02 Exercise Pandas Data Series\n",
    "The CO2 Emission data set above is not updated since 2014\n",
    "1. Create a Pandas Series with emission data from 2014 for each country or region\n",
    "2. Find the 10 Countries/Regions with the highest emissions in 2014 and show emission numbers (reverse sorted)\n",
    "3. Remove if you can those rows that are not countries (regions and aggregated groups) (hint:  [ISO 3166, Alpha-3 country codes](https://www.iban.com/country-codes), a csv file can be found here: `/data/country_codes.csv`)\n",
    "    - Find the 10 countries with highest emissions in 2014\n",
    "4. Plot the emissions of China and USA over time respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d218140e-79c2-485b-ba0a-d3423dd2795b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Create a Pandas Series with emission data from 2014 for each country or region\n"
     ]
    }
   ],
   "source": [
    "from my_modules.pandas_Ex import panda_data_series1\n",
    "panda_data_series1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44b6a62-e44d-4bbd-ab99-a9e5d2e870f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 03 Exercise pandas dataframe\n",
    "1. Using the dataframe in the above cell find:\n",
    "    1. Mean, Min, Max values for all 4 columns\n",
    "    2. The 2 dates with the largest and smallest sum (by column)\n",
    "    3. All dates where both A's and B's are positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fcbf1ff-bbda-490a-bfa7-c695b3e3e565",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              A         B         C         D\n",
      "count  6.000000  6.000000  6.000000  6.000000\n",
      "mean  -0.332751  0.349378 -0.522690 -0.284857\n",
      "std    1.011940  0.646206  1.124756  1.692247\n",
      "min   -1.059981 -0.390446 -1.285741 -2.804349\n",
      "25%   -1.015086 -0.205789 -1.154861 -1.405659\n",
      "50%   -0.621565  0.379122 -0.808393  0.162287\n",
      "75%   -0.263994  0.932640 -0.711545  0.972215\n",
      "max    1.597667  1.012082  1.716000  1.456750\n",
      "\n",
      "\n",
      "1. Mean, Min, Max values for all 4 columns\n",
      "mean for A:  -0.33275109452514434\n",
      "min for A:  -1.0599805653107361\n",
      "max for A:  1.5976669481922885\n",
      "\n",
      "\n",
      "mean for B:  0.34937794513878423\n",
      "min for B:  -0.3904459495387004\n",
      "max for B:  1.0120820986495154\n",
      "\n",
      "\n",
      "mean for C:  -0.5226900255510725\n",
      "min for C:  -1.2857412419835756\n",
      "max for C:  1.7159999164578452\n",
      "\n",
      "\n",
      "mean for D:  -0.28485705284342955\n",
      "min for D:  -2.8043490065086822\n",
      "max for D:  1.4567500713865982\n"
     ]
    }
   ],
   "source": [
    "from my_modules.pandas_Ex import panda_dataframe1a\n",
    "panda_dataframe1a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f84071b-9c20-4735-9063-351d5fb840cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. The 2 dates with the largest and smallest sum (by column)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'DatetimeIndex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmy_modules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_Ex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m panda_dataframe1b\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpanda_dataframe1b\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_notebooks/my_modules/pandas_Ex.py:130\u001b[0m, in \u001b[0;36mpanda_dataframe1b\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m4\u001b[39m), index\u001b[38;5;241m=\u001b[39mdates, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mABCD\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;66;03m# use np.random.randn to generate a dataframe of 6 by 4 random numbers\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. The 2 dates with the largest and smallest sum (by column)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdates\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11214\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.max\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11194\u001b[0m \u001b[38;5;129m@doc\u001b[39m(  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m  11195\u001b[0m     _num_doc,\n\u001b[1;32m  11196\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the maximum of the values over the requested axis.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11212\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11213\u001b[0m ):\n\u001b[0;32m> 11214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:10671\u001b[0m, in \u001b[0;36mNDFrame.max\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  10663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(\n\u001b[1;32m  10664\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10665\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10669\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  10670\u001b[0m ):\n\u001b[0;32m> 10671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10672\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10674\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10678\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:10641\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  10631\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  10632\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  10633\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10636\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  10637\u001b[0m     )\n\u001b[1;32m  10638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[1;32m  10639\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  10640\u001b[0m     )\n\u001b[0;32m> 10641\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  10643\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:9976\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   9973\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(mgr)\n\u001b[1;32m   9975\u001b[0m \u001b[38;5;66;03m# TODO: Make other agg func handle axis=None properly GH#21597\u001b[39;00m\n\u001b[0;32m-> 9976\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_axis_number\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   9977\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_agg_axis(axis)\n\u001b[1;32m   9978\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:550\u001b[0m, in \u001b[0;36mNDFrame._get_axis_number\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_axis_number\u001b[39m(\u001b[38;5;28mcls\u001b[39m, axis: Axis) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_AXIS_TO_AXIS_NUMBER\u001b[49m\u001b[43m[\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo axis named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for object type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'DatetimeIndex'"
     ]
    }
   ],
   "source": [
    "from my_modules.pandas_Ex import panda_dataframe1b\n",
    "panda_dataframe1b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e110b98-89c6-4933-945c-c5eafc1b0fd0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. All dates where both A's and B's are positive\n"
     ]
    }
   ],
   "source": [
    "from my_modules.pandas_Ex import panda_dataframe1c\n",
    "panda_dataframe1c()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937357cb-c8af-4ecb-a8c1-232fd83edb8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 04 Class Exercise\n",
    "#### Find military expenditure pr. capita.\n",
    "\n",
    "Go here and get data as csv: [worldbank military expanditure](https://databank.worldbank.org/reports.aspx?source=2&series=MS.MIL.XPND.CD&country=#). Download it manually, unzip the csv and clean up empty rows.  \n",
    "1. Use .replace() method on the dataframe to remove all data containing '..'\n",
    "2. Set index of the dataframe to be 'Country Name'\n",
    "3. Slice the 2019 column data to get a data series.\n",
    "4. Make data numeric (pd.to_numeric(data_series))\n",
    "\n",
    "1. For 2019 find the 10 countries with the highest military expenditure in USD\n",
    "2. For 2019 find the 10 countries with the highest military expenditure per capita. Find the population data here: [worldbank](https://databank.worldbank.org/source/world-development-indicators/preview/on#)(use series='Population,Total' and time='2019' and Country= countries (217)) **or** use [copy paste with this date into excel](https://www.worldometers.info/world-population/population-by-country/)\n",
    "  - (Hint: use pd.merge() to merge the mil_exp dataframe with the population dataframe on 2 columns (country_code)\n",
    "3. For 2019 find the 3 countries with the highest per capita military expenditure in the middle east\n",
    "  - [countries list with iso code](middleeast_countries.csv) or use:   \n",
    "  `list_of_middle_eastern = ['YEM','ARE','TUR','SYR','SAU','QAT','PSE','OMN','LBN','KWT','JOR','ISR','IRQ','IRN','EGY','CYP','BHR']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b00470-6e55-473a-9717-ce415feee545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7da0b87-86d4-45fd-bdf8-f80705fe5649",
   "metadata": {},
   "source": [
    "## Class Exercise: Read Titanic dataset and do some munging\n",
    "\n",
    "1. read titanic data from the data/titanic_train.csv file into a pandas dataframe\n",
    "2. set index of the dataframe to passenger id\n",
    "3. sort the dataframe by 'fare' (price of ticket)\n",
    "4. write a function to reformat a name to only contain \"firstname lastname\" (look for current format in the name column)\n",
    "5. use df.apply() to Change all names to the \"firstname lastname\" format\n",
    "6. Get only last name by the use of str method split() on comma. https://pandas.pydata.org/docs/user_guide/text.html#splitting-and-replacing-strings\n",
    "7. Get only those passengers that had one of these ticket numbers: `[350406,248706,382652,244373,345763,2649,239865]`\n",
    "8. Remove all rows without and age\n",
    "9. Convert age values to integer\n",
    "10. get only the children from the dataset\n",
    "11. Filter to get only passengers with a valid cabin\n",
    "12. Change Embarked to full name of port: C = Cherbourg; Q = Queenstown; S = Southampton\n",
    "13. create new column: 'relations' that adds sibling/spouse value with parent/child values\n",
    "14. Is there a relationship between how many relations and chances of survival?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcf99597-87fc-4124-82ee-8c84fcb97cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_modules.readTitanicDataset_Ex import test\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
