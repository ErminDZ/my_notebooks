{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ae56f8-afed-4028-843c-ec962f2498fc",
   "metadata": {},
   "source": [
    "# steps\n",
    "\n",
    "### Part 1\n",
    "1. Get data from: \"https://en.wikisource.org/wiki/Portal:State_of_the_Union_Speeches_by_United_States_Presidents\"\n",
    "2. Using BeatifullSoup get all the speeches from 1900-2022\n",
    "3. Load all speech urls into a dictionary with year as key. Hint (get year with regex: `r\"\\b(19|20)\\d{2}\\b\"`)\n",
    "4. Loop through dictionary and save content of each speech in [year].txt files\n",
    "\n",
    "### Part 2\n",
    "1. Install nltk: `pip install nltk`\n",
    "2. From the data/gdp.csv file create a dataframe with year and GDP\n",
    "3. From the data/US presidents.csv file create a dataframe with year, president and party\n",
    "4. From the developed text files in part 1, create a dictionary with year:speech\n",
    "5. Clean text by change all to lowercase and remove '\\n'\n",
    "6. Get words from texts (from nltk.tokenize import word_tokenize). Clean text by removing stop words (from nltk.corpus import stopwords) and all non-alphabetic characters (including , and .)\n",
    "7. Use from nltk.stem import WordNetLemmatizer to lemmatize all texts\n",
    "\n",
    "### Part 3\n",
    "**[TextBlob](https://textblob.readthedocs.io/en/dev/quickstart.html)** returns polarity and subjectivity of a sentence. Polarity lies between [-1,1], -1 defines a negative sentiment and 1 defines a positive sentiment. Subjectivity quantifies the amount of personal opinion and factual information contained in the text. The higher subjectivity means that the text contains personal opinion rather than factual information\n",
    "1. Install both textblob for sentiment analysis and wordclouds (pip install textblob wordclouds) and download the vader lexicon (nltk.download('vader_lexicon'))\n",
    "2. Find the polarity and subjectivity of each text (Hint: `TextBlob(text).sentiment`)\n",
    "3. Is there a correlation between negativity and recession years?\n",
    "4. Create a word cloud for the cleaned up speeches of both Trump and Obama. What can be learned from the word clouds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ece82ba-d4ff-4761-89cc-a570cc00a1be",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m listItems \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m my_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year,item \u001b[38;5;129;01min\u001b[39;00m listItems:\n\u001b[1;32m     14\u001b[0m     my_dict[item\u001b[38;5;241m.\u001b[39mtext] \u001b[38;5;241m=\u001b[39m year \u001b[38;5;241m+\u001b[39m item\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m my_dict\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "year = re.compile(r\"\\b(19|20)\\d{2}\\b\")\n",
    "r = requests.get(\"https://en.wikisource.org/wiki/Portal:State_of_the_Union_Speeches_by_United_States_Presidents\")\n",
    "r.raise_for_status()\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "listItems = soup.find_all('li')\n",
    "\n",
    "my_dict = dict()\n",
    "\n",
    "for item in listItems:\n",
    "    my_dict[item.text] = item.get('href')\n",
    "    \n",
    "my_dict\n",
    "\n",
    "#print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8360beb9-9e37-4fa2-98b6-3e5c800f5363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
