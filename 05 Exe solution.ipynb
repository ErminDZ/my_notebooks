{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab794cb2-0f59-40b1-874a-5f396e8d76e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 01 Class exercise slicing dataframe\n",
    "Use this data:\n",
    "```python\n",
    "data = np.array([['','Col1','Col2','col3'],\n",
    "                ['Row1',1,2,3],\n",
    "                ['Row2',4,5,6],\n",
    "                ['Row3',7,8,9]])\n",
    "```\n",
    "1. Create a DataFrame (wrap the data above in a pandas DataFrame in a way that printing the dataframe and its index and column attributes gives this result)  \n",
    "`pd.DataFrame(data=data[1:4,1:4], columns=data[0,1:4], index=data[1:4,0])`  \n",
    "\n",
    "``` \n",
    "     Col1 Col2 col3  \n",
    "Row1    1    2    3\n",
    "Row2    4    5    6\n",
    "Row3    7    8    9\n",
    "\n",
    "Index(['Row1', 'Row2', 'Row3'], dtype='object')\n",
    "Index(['Col1', 'Col2', 'col3'], dtype='object')\n",
    "```\n",
    "\n",
    "2. Make slices of data:\n",
    "   1. second column using column name\n",
    "   2. third column using column index (.iloc[])\n",
    "   3. slice element at third row of second column (use .iloc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc16e8a-db05-4383-aefb-f8dd80987d70",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Create a DataFrame (wrap the data above in a pandas DataFrame in a way that printing the dataframe and its index and column attributes gives this result)\n",
      "     Col1 Col2 col3\n",
      "Row1    1    2    3\n",
      "Row2    4    5    6\n",
      "Row3    7    8    9\n",
      "\n",
      "\n",
      "Index(['Row1', 'Row2', 'Row3'], dtype='object')\n",
      "Index(['Col1', 'Col2', 'col3'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from my_modules.pandas_Ex import slicing_dataframe1\n",
    "slicing_dataframe1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829f3a18-c8c1-4037-b1af-aa14112e98bc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. second column using column name\n",
      "Row1    2\n",
      "Row2    5\n",
      "Row3    8\n",
      "Name: Col2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from my_modules.pandas_Ex import slicing_dataframe2a\n",
    "slicing_dataframe2a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e31ea5cb-cc36-4b99-9918-84030ac5581d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. third column using column index (.iloc[])\n",
      "Row1    3\n",
      "Row2    6\n",
      "Row3    9\n",
      "Name: col3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from my_modules.pandas_Ex import slicing_dataframe2b\n",
    "slicing_dataframe2b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "425f3d35-7e58-41de-b56e-12821120c209",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. slice element at third row of second column (use .iloc())\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "from my_modules.pandas_Ex import slicing_dataframe2c\n",
    "slicing_dataframe2c()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3739343b-8cbe-4e3f-9984-79751cfbdedd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 02 Exercise Pandas Data Series\n",
    "The CO2 Emission data set above is not updated since 2014\n",
    "1. Create a Pandas Series with emission data from 2014 for each country or region\n",
    "2. Find the 10 Countries/Regions with the highest emissions in 2014 and show emission numbers (reverse sorted)\n",
    "3. Remove if you can those rows that are not countries (regions and aggregated groups) (hint:  [ISO 3166, Alpha-3 country codes](https://www.iban.com/country-codes), a csv file can be found here: `/data/country_codes.csv`)\n",
    "    - Find the 10 countries with highest emissions in 2014\n",
    "4. Plot the emissions of China and USA over time respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d218140e-79c2-485b-ba0a-d3423dd2795b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Create a Pandas Series with emission data from 2014 for each country or region\n"
     ]
    }
   ],
   "source": [
    "from my_modules.pandas_Ex import panda_data_series1\n",
    "panda_data_series1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44b6a62-e44d-4bbd-ab99-a9e5d2e870f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 03 Exercise pandas dataframe\n",
    "1. Using the dataframe in the above cell find:\n",
    "    1. Mean, Min, Max values for all 4 columns\n",
    "    2. The 2 dates with the largest and smallest sum (by column)\n",
    "    3. All dates where both A's and B's are positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fcbf1ff-bbda-490a-bfa7-c695b3e3e565",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              A         B         C         D\n",
      "count  6.000000  6.000000  6.000000  6.000000\n",
      "mean  -0.332751  0.349378 -0.522690 -0.284857\n",
      "std    1.011940  0.646206  1.124756  1.692247\n",
      "min   -1.059981 -0.390446 -1.285741 -2.804349\n",
      "25%   -1.015086 -0.205789 -1.154861 -1.405659\n",
      "50%   -0.621565  0.379122 -0.808393  0.162287\n",
      "75%   -0.263994  0.932640 -0.711545  0.972215\n",
      "max    1.597667  1.012082  1.716000  1.456750\n",
      "\n",
      "\n",
      "1. Mean, Min, Max values for all 4 columns\n",
      "mean for A:  -0.33275109452514434\n",
      "min for A:  -1.0599805653107361\n",
      "max for A:  1.5976669481922885\n",
      "\n",
      "\n",
      "mean for B:  0.34937794513878423\n",
      "min for B:  -0.3904459495387004\n",
      "max for B:  1.0120820986495154\n",
      "\n",
      "\n",
      "mean for C:  -0.5226900255510725\n",
      "min for C:  -1.2857412419835756\n",
      "max for C:  1.7159999164578452\n",
      "\n",
      "\n",
      "mean for D:  -0.28485705284342955\n",
      "min for D:  -2.8043490065086822\n",
      "max for D:  1.4567500713865982\n"
     ]
    }
   ],
   "source": [
    "from my_modules.pandas_Ex import panda_dataframe1a\n",
    "panda_dataframe1a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f84071b-9c20-4735-9063-351d5fb840cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. The 2 dates with the largest and smallest sum (by column)\n",
      "                   A         B         C         D\n",
      "2020-06-02 -1.299986 -0.730526 -0.495252 -1.145776\n",
      "2020-06-03  0.079060  0.673573  0.299987 -2.053915\n",
      "2020-06-04  0.415610  0.192243  0.424896  0.800340\n",
      "2020-06-05  0.566635  0.036293  0.107438 -0.824265\n",
      "2020-06-06 -0.080615  0.503199  0.623298  0.144070\n",
      "2020-06-07 -0.544172 -0.183448 -0.549969  0.101124\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmy_modules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_Ex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m panda_dataframe1b\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpanda_dataframe1b\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_notebooks/my_modules/pandas_Ex.py:132\u001b[0m, in \u001b[0;36mpanda_dataframe1b\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. The 2 dates with the largest and smallest sum (by column)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin for A: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mdates\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmin())\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax for A: \u001b[39m\u001b[38;5;124m\"\u001b[39m, dates[:]\u001b[38;5;241m.\u001b[39mmax())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:5055\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m   5049\u001b[0m     \u001b[38;5;66;03m# if we have list[bools, length=1e5] then doing this check+convert\u001b[39;00m\n\u001b[1;32m   5050\u001b[0m     \u001b[38;5;66;03m#  takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__\u001b[39;00m\n\u001b[1;32m   5051\u001b[0m     \u001b[38;5;66;03m#  time below from 3.8 ms to 496 µs\u001b[39;00m\n\u001b[1;32m   5052\u001b[0m     \u001b[38;5;66;03m# if we already have ndarray[bool], the overhead is 1.4 µs or .25%\u001b[39;00m\n\u001b[1;32m   5053\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m-> 5055\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5056\u001b[0m \u001b[38;5;66;03m# Because we ruled out integer above, we always get an arraylike here\u001b[39;00m\n\u001b[1;32m   5057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/arrays/datetimelike.py:341\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mThis getitem defers to the underlying array, which by-definition can\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03monly handle list-likes, slices, and integer scalars\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# Use cast as we know we will get back a DatetimeLikeArray or DTScalar,\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# but skip evaluating the Union at runtime for performance\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# (see https://github.com/pandas-dev/pandas/pull/44624)\u001b[39;00m\n\u001b[1;32m    340\u001b[0m result \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnion[DatetimeLikeArrayT, DTScalarOrNaT]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m )\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_scalar(result):\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/arrays/_mixins.py:281\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    279\u001b[0m key \u001b[38;5;241m=\u001b[39m extract_array(key, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    280\u001b[0m key \u001b[38;5;241m=\u001b[39m check_array_indexer(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[0;32m--> 281\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ndarray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_scalar(result):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_box_func(result)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "from my_modules.pandas_Ex import panda_dataframe1b\n",
    "panda_dataframe1b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e110b98-89c6-4933-945c-c5eafc1b0fd0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. All dates where both A's and B's are positive\n"
     ]
    }
   ],
   "source": [
    "from my_modules.pandas_Ex import panda_dataframe1c\n",
    "panda_dataframe1c()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937357cb-c8af-4ecb-a8c1-232fd83edb8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 04 Class Exercise\n",
    "#### Find military expenditure pr. capita.\n",
    "\n",
    "Go here and get data as csv: [worldbank military expanditure](https://databank.worldbank.org/reports.aspx?source=2&series=MS.MIL.XPND.CD&country=#). Download it manually, unzip the csv and clean up empty rows.  \n",
    "1. Use .replace() method on the dataframe to remove all data containing '..'\n",
    "2. Set index of the dataframe to be 'Country Name'\n",
    "3. Slice the 2019 column data to get a data series.\n",
    "4. Make data numeric (pd.to_numeric(data_series))\n",
    "\n",
    "1. For 2019 find the 10 countries with the highest military expenditure in USD\n",
    "2. For 2019 find the 10 countries with the highest military expenditure per capita. Find the population data here: [worldbank](https://databank.worldbank.org/source/world-development-indicators/preview/on#)(use series='Population,Total' and time='2019' and Country= countries (217)) **or** use [copy paste with this date into excel](https://www.worldometers.info/world-population/population-by-country/)\n",
    "  - (Hint: use pd.merge() to merge the mil_exp dataframe with the population dataframe on 2 columns (country_code)\n",
    "3. For 2019 find the 3 countries with the highest per capita military expenditure in the middle east\n",
    "  - [countries list with iso code](middleeast_countries.csv) or use:   \n",
    "  `list_of_middle_eastern = ['YEM','ARE','TUR','SYR','SAU','QAT','PSE','OMN','LBN','KWT','JOR','ISR','IRQ','IRN','EGY','CYP','BHR']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b00470-6e55-473a-9717-ce415feee545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
